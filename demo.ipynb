{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To run please install the [.NET Interactive Notebooks](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) extension for Visual Studio Code. (When opening the first it will install .NET Interactive)* Trouble? Check out https://github.com/dotnet/interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "// This may take over a minute\n",
    "#i \"nuget:https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet5/nuget/v3/index.json\" \n",
    "#i \"nuget:https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-tools/nuget/v3/index.json\" \n",
    "\n",
    "#r \"nuget:Microsoft.ML, 1.7.0\"\n",
    "#r \"nuget:Microsoft.ML.AutoML, 0.19.0\"\n",
    "#r \"nuget:Microsoft.Data.Analysis, 0.19.0\"\n",
    "#r \"nuget:XPlot.Plotly.Interactive, 4.0.6\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\r\n",
       "<div style=\"width: 400px; height: 400px;\" id=\"a5a513d8-5c7d-4bb7-b949-9d9cf9adce1a\"></div><script type=\"text/javascript\">\r\n",
       "\n",
       "var renderPlotly = function() {\n",
       "    var xplotRequire = require.config({context:'xplot-3.0.1',paths:{plotly:'https://cdn.plot.ly/plotly-1.49.2.min'}}) || require;\n",
       "    xplotRequire(['plotly'], function(Plotly) { \r\n",
       "\n",
       "            var data = [{\"type\":\"scattergl\",\"x\":[1.1221147,-0.8188294,1.6137097,-0.92300916,0.14385146,0.16447246,1.3387706,0.8711486,1.8312994,0.4875712,0.03746235,-0.44391686,-0.8122295,1.6355231,0.47353902,0.75354934,0.26421282,1.4275572,-0.37235606,-0.961302,0.78085846,0.91660905,1.0470381,-0.060363054,0.029189538,-0.39573225,-0.10464591,1.8811,0.8274088,1.2977711,-0.6768929,0.5295299,-0.8438023,0.2659847,0.13740386,-0.9104394,1.3374003,1.0225772,1.0249013,-0.7508959,1.2028164,-0.4691021,0.7408367,0.7869051,-0.13005191,0.8040231,0.28330368,-0.7110554,0.30262452,0.8079146,-0.9416269,1.1408149,-0.15713753,1.7150437,0.37246576,-0.74309576,0.6814249,0.86861247,1.0022957,-1.0221939,-0.6107626,-0.77668303,1.1053001,-0.1789046,0.40498304,1.814573,-0.79128563,1.9817315,0.73242795,2.1114166,2.162056,0.8962454,0.37349376,0.5849646,0.17632979,0.109115645,0.29753274,0.096046574,0.47464365,1.1163471,0.5536276,0.1895281,1.9456692,-0.08462662,1.16858,0.12446847,2.0338993,-0.028000537,0.7409348,0.79394704,0.86874264,1.6187444,1.4298656,1.9748044,1.8535634,1.7491217,-0.6856689,1.7523743,0.18078955,0.12108297],\"y\":[0.08147717,0.058790065,-0.1246459,0.3652289,0.04438005,0.11738346,-0.23800993,-0.4227176,-0.14104383,0.6390928,0.4235881,0.8967393,0.9120909,-0.34999675,0.9573426,0.62372714,-0.24241982,-0.37251034,0.9566917,0.3260901,0.7974894,-0.42763844,-0.5444925,0.11960909,0.306839,0.8965439,1.1178831,0.29920256,0.34497717,-0.36654314,0.8555996,0.9473559,0.60473984,0.887322,0.3978569,-0.097096644,-0.36741197,-0.3975265,-0.5486393,0.25328773,0.08115382,0.78079623,0.45923254,0.76624745,1.1193894,-0.42315447,-0.21944071,0.7116388,-0.09338909,0.3365383,0.16801858,-0.46289718,0.9321066,-0.18362008,-0.12607841,0.69895166,0.68563426,-0.37278616,0.21687478,0.3975082,0.8311714,0.64360934,0.2191628,1.0695977,0.82647836,0.034525376,0.20006882,0.46076053,-0.39965755,0.18064071,0.49423382,0.46153605,1.044983,-0.32125983,0.19745572,0.481557,0.9958364,-0.046269864,-0.10512648,-0.41553438,-0.42312583,1.0183566,-0.0953034,1.0726234,-0.02848107,1.0572503,0.2847298,0.17076764,0.4141144,0.5597258,-0.5301472,-0.3258453,-0.4733421,-0.17793162,0.34226397,0.028339025,0.46535695,0.16452052,-0.00029541762,1.0655522],\"mode\":\"markers\",\"marker\":{\"color\":[-1.0,-1.0,1.0,-1.0,1.0,1.0,1.0,1.0,1.0,-1.0,1.0,-1.0,-1.0,1.0,-1.0,-1.0,1.0,1.0,-1.0,-1.0,-1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,1.0,-1.0,1.0,-1.0,-1.0,-1.0,-1.0,1.0,-1.0,1.0,1.0,1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,1.0,1.0,-1.0,1.0,-1.0,-1.0,1.0,-1.0,1.0,1.0,-1.0,-1.0,1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,1.0,-1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,1.0,1.0,1.0,-1.0,1.0,1.0,1.0,1.0,-1.0,1.0,-1.0,-1.0,-1.0,1.0,1.0,-1.0,-1.0,1.0,1.0,1.0,1.0,1.0,1.0,-1.0,1.0,1.0,-1.0],\"colorscale\":\"Jet\"}}];\n",
       "           var layout = \"\";\n",
       "           Plotly.newPlot('a5a513d8-5c7d-4bb7-b949-9d9cf9adce1a', data, layout);\n",
       "        \r\n",
       "});\n",
       "};\r\n",
       "// ensure `require` is available globally\r\n",
       "if ((typeof(require) !==  typeof(Function)) || (typeof(require.config) !== typeof(Function))) {\r\n",
       "    let require_script = document.createElement('script');\r\n",
       "    require_script.setAttribute('src', 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js');\r\n",
       "    require_script.setAttribute('type', 'text/javascript');\r\n",
       "    \r\n",
       "    \r\n",
       "    require_script.onload = function() {\r\n",
       "        renderPlotly();\r\n",
       "    };\r\n",
       "\r\n",
       "    document.getElementsByTagName('head')[0].appendChild(require_script);\r\n",
       "}\r\n",
       "else {\r\n",
       "    renderPlotly();\r\n",
       "}\r\n",
       "\r\n",
       "</script>\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using static Microsoft.DotNet.Interactive.Formatting.PocketViewTags;\n",
    "using Microsoft.DotNet.Interactive.Formatting;\n",
    "using Microsoft.Data.Analysis;\n",
    "using XPlot.Plotly;\n",
    "\n",
    "var data = DataFrame.LoadCsv(\"data/labeled_data.csv\");\n",
    "\n",
    "var chart = Chart.Plot(\n",
    "    new Scattergl()\n",
    "    {\n",
    "        x = data.Columns[\"x\"],\n",
    "        y = data.Columns[\"y\"],\n",
    "        mode = \"markers\",\n",
    "        marker = new Marker()\n",
    "        {\n",
    "            color = data.Columns[\"label\"],\n",
    "            colorscale = \"Jet\"\n",
    "        }\n",
    "    }\n",
    ");\n",
    "\n",
    "chart.Width = 400;\n",
    "chart.Height = 400;\n",
    "chart.Display();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "// One day we can import projects or files\n",
    "// TODO import NMicorgrad.dll\n",
    "\n",
    "#r \"NMicrograd\\bin\\Debug\\net6.0\\NMicrograd.dll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Please see the notebook in the `data` folder for the steps how these were captures\n",
    "var lines = System.IO.File.ReadAllLines(\"data\\\\labeled_data.csv\").Skip(1);\n",
    "\n",
    "// Format is x1, x2, label\n",
    "var data = lines.Select( l => l.Split(',')) \n",
    "   .Select( a => new {\n",
    "        X = new []{double.Parse(a[0]), double.Parse(a[1])},\n",
    "        Y = int.Parse(a[2])});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP of [Layer of [ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2),ReLUNeuron(2)],Layer of [ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16),ReLUNeuron(16)],Layer of [LinearNeuron(16)]]\r\n",
      "Number of parameters: 337\r\n"
     ]
    }
   ],
   "source": [
    "using NMicrograd;\n",
    "\n",
    "var model = new MLP(2, new []{16, 16, 1}); // 2-layer neural network\n",
    "\n",
    "Console.WriteLine(model);\n",
    "Console.WriteLine($\"Number of parameters: {model.GetParameters().Count()}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.IO;\n",
    "\n",
    "// Optional\n",
    "// Copies exact weights used in the https://github.com/karpathy/micrograd/blob/master/demo.ipynb (from 14 Apr 2020)\n",
    "// so that the descent is exactly the same\n",
    "// Please see the notebook in the `data` folder for the steps how these were captures\n",
    "var weights = File.ReadAllText(\"data\\\\weights_data.csv\")\n",
    "    .Split(',')\n",
    "    .Select( s => double.Parse(s));\n",
    "\n",
    "if(model.GetParameters().Count() != weights.Count())\n",
    "{\n",
    "    throw new Exception($\"Bad weights. Has {weights.Count()}, need {model.GetParameters().Count()}\");\n",
    "}\n",
    "\n",
    "// Fill the weights\n",
    "foreach((var p, var w) in model.GetParameters().Zip(weights, (p,w) => (p,w)))\n",
    "    p.Data = w; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "static (Value TotalLoss, double Accuracy) GetLoss(\n",
    "    IEnumerable<IEnumerable<double>> x,\n",
    "    IEnumerable<int> y,\n",
    "    MLP model)\n",
    "{\n",
    "    var inputs = x.Select( d => d.Select( x => new Value(data: x)));\n",
    "\n",
    "    // forward the model to get scores\n",
    "    var scores = inputs.Select(input => model.F(input).First());\n",
    "\n",
    "    // svm \"max-margin\" loss\n",
    "    var losses = y.Zip(scores, (yi, scorei) => (1 + -yi*scorei).ReLU());\n",
    "    \n",
    "    // var data_loss = new Value(0);\n",
    "    // foreach(var l in losses) data_loss+=l;\n",
    "    // data_loss = data_loss * (1.0 / losses.Count());\n",
    "    var data_loss = losses.Aggregate(new Value(0), (s,d) => s+d) * (1.0 / losses.Count());\n",
    "\n",
    "    // L2 regularization\n",
    "    var alpha = 1e-4;\n",
    "    //var reg_loss = new Value(0);\n",
    "    //model.GetParameters().Select(p => p*p).ToList().ForEach(p2 => reg_loss += p2); \n",
    "    //reg_loss = alpha * reg_loss;\n",
    "    var reg_loss = alpha * model.GetParameters().Aggregate(new Value(0), (s,d) => s+(d*d));\n",
    "    var total_loss = data_loss + reg_loss;\n",
    "    \n",
    "    // also get accuracy\n",
    "    var accuracy = y.Zip(scores, (yi, scorei) => (yi > 0) == (scorei.Data > 0));\n",
    "    return (TotalLoss: total_loss, Accuracy: accuracy!.Sum(a => a ? 1.0 : 0) / accuracy!.Count());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 0.89584410286832217, accuracy 50.0%\r\n",
      "step 1 loss 1.72359053369720128, accuracy 81.0%\r\n",
      "step 2 loss 0.74290063138511309, accuracy 77.0%\r\n",
      "step 3 loss 0.77056412605842017, accuracy 82.0%\r\n",
      "step 4 loss 0.36927933859765377, accuracy 84.0%\r\n",
      "step 5 loss 0.31354548191852194, accuracy 86.0%\r\n",
      "step 6 loss 0.28142343497724337, accuracy 89.0%\r\n",
      "step 7 loss 0.26888733313983904, accuracy 91.0%\r\n",
      "step 8 loss 0.25671472860574168, accuracy 91.0%\r\n",
      "step 9 loss 0.27048625516379227, accuracy 91.0%\r\n",
      "step 10 loss 0.24507023853658050, accuracy 91.0%\r\n",
      "step 11 loss 0.25099055297915035, accuracy 92.0%\r\n",
      "step 12 loss 0.21560951851922952, accuracy 91.0%\r\n",
      "step 13 loss 0.23090378446402726, accuracy 93.0%\r\n",
      "step 14 loss 0.20152151227899456, accuracy 92.0%\r\n",
      "step 15 loss 0.22574506279282219, accuracy 93.0%\r\n",
      "step 16 loss 0.19447987596204114, accuracy 92.0%\r\n",
      "step 17 loss 0.21089496199246355, accuracy 93.0%\r\n",
      "step 18 loss 0.15983077356303607, accuracy 94.0%\r\n",
      "step 19 loss 0.18453748746883916, accuracy 93.0%\r\n",
      "step 20 loss 0.18977522856087639, accuracy 91.0%\r\n",
      "step 21 loss 0.19072704042579647, accuracy 93.0%\r\n",
      "step 22 loss 0.11733695088756486, accuracy 97.0%\r\n",
      "step 23 loss 0.12173524408232458, accuracy 95.0%\r\n",
      "step 24 loss 0.12615712612770452, accuracy 95.0%\r\n",
      "step 25 loss 0.16049097780801680, accuracy 95.0%\r\n",
      "step 26 loss 0.18747197705245802, accuracy 92.0%\r\n",
      "step 27 loss 0.16741837891059413, accuracy 95.0%\r\n",
      "step 28 loss 0.09586583491455403, accuracy 97.0%\r\n",
      "step 29 loss 0.08778783707420916, accuracy 96.0%\r\n",
      "step 30 loss 0.11731297569011853, accuracy 95.0%\r\n",
      "step 31 loss 0.09340146460619839, accuracy 97.0%\r\n",
      "step 32 loss 0.12454454903103457, accuracy 95.0%\r\n",
      "step 33 loss 0.07984002652777274, accuracy 97.0%\r\n",
      "step 34 loss 0.07727519232921680, accuracy 97.0%\r\n",
      "step 35 loss 0.07661250143094478, accuracy 98.0%\r\n",
      "step 36 loss 0.10610492379198373, accuracy 96.0%\r\n",
      "step 37 loss 0.09062808429265980, accuracy 99.0%\r\n",
      "step 38 loss 0.10671887043036932, accuracy 95.0%\r\n",
      "step 39 loss 0.05225659921975852, accuracy 98.0%\r\n",
      "step 40 loss 0.06016009895234468, accuracy 100.0%\r\n",
      "step 41 loss 0.08596724533333938, accuracy 96.0%\r\n",
      "step 42 loss 0.05112107943179602, accuracy 99.0%\r\n",
      "step 43 loss 0.05240142401642834, accuracy 97.0%\r\n",
      "step 44 loss 0.04530684179001575, accuracy 100.0%\r\n",
      "step 45 loss 0.07211073370655093, accuracy 97.0%\r\n",
      "step 46 loss 0.03334238651310238, accuracy 99.0%\r\n",
      "step 47 loss 0.03143222795751124, accuracy 100.0%\r\n",
      "step 48 loss 0.03658536747111510, accuracy 99.0%\r\n",
      "step 49 loss 0.04829139382390310, accuracy 99.0%\r\n",
      "step 50 loss 0.09875114765619626, accuracy 96.0%\r\n",
      "step 51 loss 0.05449063965875452, accuracy 99.0%\r\n",
      "step 52 loss 0.03392679435708314, accuracy 100.0%\r\n",
      "step 53 loss 0.05261517263568440, accuracy 97.0%\r\n",
      "step 54 loss 0.03250295251424922, accuracy 99.0%\r\n",
      "step 55 loss 0.02888327387207826, accuracy 100.0%\r\n",
      "step 56 loss 0.04139151104027238, accuracy 98.0%\r\n",
      "step 57 loss 0.01898740742612853, accuracy 100.0%\r\n",
      "step 58 loss 0.02523833523883737, accuracy 100.0%\r\n",
      "step 59 loss 0.02079656521341900, accuracy 100.0%\r\n",
      "step 60 loss 0.03259711157810224, accuracy 99.0%\r\n",
      "step 61 loss 0.01786335169348037, accuracy 100.0%\r\n",
      "step 62 loss 0.02300871783221165, accuracy 100.0%\r\n",
      "step 63 loss 0.02207932546358160, accuracy 100.0%\r\n",
      "step 64 loss 0.02943291785352957, accuracy 99.0%\r\n",
      "step 65 loss 0.01625151464409205, accuracy 100.0%\r\n",
      "step 66 loss 0.02846853448326437, accuracy 99.0%\r\n",
      "step 67 loss 0.01399436554620871, accuracy 100.0%\r\n",
      "step 68 loss 0.01555234484365157, accuracy 100.0%\r\n",
      "step 69 loss 0.03389119946160163, accuracy 99.0%\r\n",
      "step 70 loss 0.01422987006592689, accuracy 100.0%\r\n",
      "step 71 loss 0.01325528158328548, accuracy 100.0%\r\n",
      "step 72 loss 0.01230027759002204, accuracy 100.0%\r\n",
      "step 73 loss 0.01267605249835609, accuracy 100.0%\r\n",
      "step 74 loss 0.02059381195595470, accuracy 100.0%\r\n",
      "step 75 loss 0.01184539820536442, accuracy 100.0%\r\n",
      "step 76 loss 0.01601269747288325, accuracy 100.0%\r\n",
      "step 77 loss 0.02545836023922207, accuracy 100.0%\r\n",
      "step 78 loss 0.01438293028966188, accuracy 100.0%\r\n",
      "step 79 loss 0.01169896242581796, accuracy 100.0%\r\n",
      "step 80 loss 0.01231850080051583, accuracy 100.0%\r\n",
      "step 81 loss 0.01412111703146420, accuracy 100.0%\r\n",
      "step 82 loss 0.01166459196244619, accuracy 100.0%\r\n",
      "step 83 loss 0.01158931454918874, accuracy 100.0%\r\n",
      "step 84 loss 0.01099029934773522, accuracy 100.0%\r\n",
      "step 85 loss 0.01098922672069161, accuracy 100.0%\r\n",
      "step 86 loss 0.01098819375765507, accuracy 100.0%\r\n",
      "step 87 loss 0.01098720044738870, accuracy 100.0%\r\n",
      "step 88 loss 0.01098624677908492, accuracy 100.0%\r\n",
      "step 89 loss 0.01098533274236527, accuracy 100.0%\r\n",
      "step 90 loss 0.01098445832728018, accuracy 100.0%\r\n",
      "step 91 loss 0.01098362352430886, accuracy 100.0%\r\n",
      "step 92 loss 0.01098282832435907, accuracy 100.0%\r\n",
      "step 93 loss 0.01098207271876700, accuracy 100.0%\r\n",
      "step 94 loss 0.01098135669929704, accuracy 100.0%\r\n",
      "step 95 loss 0.01098068025814172, accuracy 100.0%\r\n",
      "step 96 loss 0.01098004338792151, accuracy 100.0%\r\n",
      "step 97 loss 0.01097944608168467, accuracy 100.0%\r\n",
      "step 98 loss 0.01097888833290723, accuracy 100.0%\r\n",
      "step 99 loss 0.01097837013549272, accuracy 100.0%\r\n"
     ]
    }
   ],
   "source": [
    "// Actual training\n",
    "for(int k = 0; k<100; k++)\n",
    "{\n",
    "    // forward\n",
    "    (var total_loss, var acc) = GetLoss(\n",
    "        x: data.Select(d => d.X), \n",
    "        y: data.Select(d => d.Y),\n",
    "        model);\n",
    "    \n",
    "    // backward\n",
    "    model.ZeroTheGrads();\n",
    "    total_loss.Backward();\n",
    "    \n",
    "    // update (stochastic gradient descent)\n",
    "    var learning_rate = 1.0 - (0.9*k)/100;\n",
    "    foreach(var p in model.GetParameters())\n",
    "        p.Data -= learning_rate * p.Grad;\n",
    "\n",
    "    if (k % 1 == 0)\n",
    "        Console.WriteLine($\"step {k} loss {string.Format(\"{0:F17}\", total_loss.Data)}, accuracy {acc*100:0.0}%\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "vscode": {
     "languageId": "dotnet-interactive.csharp"
    }
   },
   "outputs": [],
   "source": [
    "// TODO capture decision boudary at every n steps and create a gif from them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "C#"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
