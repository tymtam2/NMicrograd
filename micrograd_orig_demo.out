Copy paste of https://github.com/karpathy/micrograd/blob/master/demo.ipynb on 2022 Sep 25
step 0 loss 0.8958441028683222, accuracy 50.0%
step 1 loss 1.7235905336972022, accuracy 81.0%
step 2 loss 0.7429006313851131, accuracy 77.0%
step 3 loss 0.7705641260584198, accuracy 82.0%
step 4 loss 0.3692793385976538, accuracy 84.0%
step 5 loss 0.313545481918522, accuracy 86.0%
step 6 loss 0.2814234349772435, accuracy 89.0%
step 7 loss 0.26888733313983904, accuracy 91.0%
step 8 loss 0.2567147286057417, accuracy 91.0%
step 9 loss 0.2704862551637922, accuracy 91.0%
step 10 loss 0.24507023853658053, accuracy 91.0%
step 11 loss 0.2509905529791503, accuracy 92.0%
step 12 loss 0.21560951851922952, accuracy 91.0%
step 13 loss 0.23090378446402726, accuracy 93.0%
step 14 loss 0.20152151227899445, accuracy 92.0%
step 15 loss 0.22574506279282217, accuracy 93.0%
step 16 loss 0.19447987596204114, accuracy 92.0%
step 17 loss 0.21089496199246363, accuracy 93.0%
step 18 loss 0.159830773563036, accuracy 94.0%
step 19 loss 0.1845374874688392, accuracy 93.0%
step 20 loss 0.18977522856087634, accuracy 91.0%
step 21 loss 0.19072704042579647, accuracy 93.0%
step 22 loss 0.11733695088756485, accuracy 97.0%
step 23 loss 0.12173524408232454, accuracy 95.0%
step 24 loss 0.1261571261277045, accuracy 95.0%
step 25 loss 0.16049097780801674, accuracy 95.0%
step 26 loss 0.18747197705245805, accuracy 92.0%
step 27 loss 0.16741837891059408, accuracy 95.0%
step 28 loss 0.09586583491455399, accuracy 97.0%
step 29 loss 0.0877878370742091, accuracy 96.0%
step 30 loss 0.11731297569011848, accuracy 95.0%
step 31 loss 0.09340146460619836, accuracy 97.0%
step 32 loss 0.12454454903103446, accuracy 95.0%
step 33 loss 0.07984002652777272, accuracy 97.0%
step 34 loss 0.07727519232921673, accuracy 97.0%
step 35 loss 0.07661250143094483, accuracy 98.0%
step 36 loss 0.10610492379198365, accuracy 96.0%
step 37 loss 0.09062808429265976, accuracy 99.0%
step 38 loss 0.10671887043036932, accuracy 95.0%
step 39 loss 0.05225659921975849, accuracy 98.0%
step 40 loss 0.06016009895234464, accuracy 100.0%
step 41 loss 0.08596724533333942, accuracy 96.0%
step 42 loss 0.051121079431796, accuracy 99.0%
step 43 loss 0.052401424016428284, accuracy 97.0%
step 44 loss 0.045306841790015734, accuracy 100.0%
step 45 loss 0.07211073370655095, accuracy 97.0%
step 46 loss 0.03334238651310234, accuracy 99.0%
step 47 loss 0.03143222795751122, accuracy 100.0%
step 48 loss 0.03658536747111507, accuracy 99.0%
step 49 loss 0.04829139382390309, accuracy 99.0%
step 50 loss 0.09875114765619622, accuracy 96.0%
step 51 loss 0.05449063965875453, accuracy 99.0%
step 52 loss 0.03392679435708309, accuracy 100.0%
step 53 loss 0.05261517263568441, accuracy 97.0%
step 54 loss 0.03250295251424923, accuracy 99.0%
step 55 loss 0.02888327387207822, accuracy 100.0%
step 56 loss 0.04139151104027239, accuracy 98.0%
step 57 loss 0.018987407426128502, accuracy 100.0%
step 58 loss 0.0252383352388374, accuracy 100.0%
step 59 loss 0.02079656521341895, accuracy 100.0%
step 60 loss 0.0325971115781023, accuracy 99.0%
step 61 loss 0.017863351693480307, accuracy 100.0%
step 62 loss 0.023008717832211683, accuracy 100.0%
step 63 loss 0.022079325463581503, accuracy 100.0%
step 64 loss 0.029432917853529684, accuracy 99.0%
step 65 loss 0.01625151464409193, accuracy 100.0%
step 66 loss 0.02846853448326446, accuracy 99.0%
step 67 loss 0.013994365546208731, accuracy 100.0%
step 68 loss 0.015552344843651405, accuracy 100.0%
step 69 loss 0.0338911994616017, accuracy 99.0%
step 70 loss 0.014229870065926908, accuracy 100.0%
step 71 loss 0.013255281583285504, accuracy 100.0%
step 72 loss 0.012300277590022063, accuracy 100.0%
step 73 loss 0.012676052498355976, accuracy 100.0%
step 74 loss 0.020593811955954763, accuracy 100.0%
step 75 loss 0.011845398205364453, accuracy 100.0%
step 76 loss 0.016012697472883086, accuracy 100.0%
step 77 loss 0.025458360239222128, accuracy 100.0%
step 78 loss 0.014382930289661911, accuracy 100.0%
step 79 loss 0.011698962425817985, accuracy 100.0%
step 80 loss 0.012318500800515763, accuracy 100.0%
step 81 loss 0.014121117031464233, accuracy 100.0%
step 82 loss 0.011664591962446225, accuracy 100.0%
step 83 loss 0.011589314549188726, accuracy 100.0%
step 84 loss 0.010990299347735226, accuracy 100.0%
step 85 loss 0.01098922672069161, accuracy 100.0%
step 86 loss 0.010988193757655071, accuracy 100.0%
step 87 loss 0.010987200447388707, accuracy 100.0%
step 88 loss 0.010986246779084925, accuracy 100.0%
step 89 loss 0.010985332742365272, accuracy 100.0%
step 90 loss 0.010984458327280174, accuracy 100.0%
step 91 loss 0.010983623524308862, accuracy 100.0%
step 92 loss 0.010982828324359073, accuracy 100.0%
step 93 loss 0.010982072718767003, accuracy 100.0%
step 94 loss 0.010981356699297042, accuracy 100.0%
step 95 loss 0.010980680258141723, accuracy 100.0%
step 96 loss 0.010980043387921506, accuracy 100.0%
step 97 loss 0.010979446081684675, accuracy 100.0%
step 98 loss 0.010978888332907229, accuracy 100.0%
step 99 loss 0.010978370135492717, accuracy 100.0%